# Topic: Troubleshoot Clusters and Nodes

### 1. Theory
Troubleshooting clusters and nodes is a core skill for Kubernetes administrators, as it involves diagnosing and resolving issues across the entire cluster architecture, from the control plane to worker nodes. This topic focuses on identifying failure points in **cluster components** (control plane and nodes) and restoring cluster health.

- **Cluster Architecture**:
  - Kubernetes clusters consist of a **control plane** (managing cluster state) and **worker nodes** (running workloads).
  - Understanding component roles and interactions is critical for pinpointing issues (e.g., API server downtime affecting scheduling).
  - Tools like `kubectl get nodes` and `kubectl cluster-info` provide high-level health checks.

- **Node Issues**:
  - Nodes can enter `NotReady` states due to kubelet failures, resource exhaustion, or network problems.
  - Conditions like `DiskPressure` or `MemoryPressure` indicate resource constraints, triggering pod evictions or scheduling blocks.
  - Maintenance tasks (e.g., cordon, drain) isolate nodes for troubleshooting or upgrades.

- **Control Plane Issues**:
  - The control plane (API server, scheduler, controller manager, etcd) is the clusterâ€™s brain, and failures here disrupt all operations.
  - Issues include pod crashes, etcd quorum loss, or API server connectivity problems.
  - Logs and pod status in the `kube-system` namespace are key diagnostic tools.

**Why It Matters for CKA**:
- The CKA exam tests your ability to troubleshoot live clusters under time pressure, often requiring you to fix nodes or control plane components.
- Tasks involve inspecting statuses, logs, and configurations, reflecting real-world cluster administration challenges.

**Big Picture**:
- Cluster troubleshooting starts with a top-down approach: check cluster health, then drill into nodes or control plane.
- Nodes handle workloads, while the control plane manages stateâ€”failures in either can cascade, requiring quick diagnosis.
- Effective troubleshooting combines `kubectl` commands, system logs, and component-specific tools (e.g., `crictl`).

---

### 2. Key Concepts and Components
#### Cluster Architecture
- **Control Plane Components**:
  - **kube-apiserver**: Handles API requests, the clusterâ€™s entry point.
  - **kube-controller-manager**: Runs controllers (e.g., ReplicaSet, Node).
  - **kube-scheduler**: Assigns pods to nodes based on resources and constraints.
  - **etcd**: Distributed key-value store for cluster state.
- **Worker Node Components**:
  - **kubelet**: Manages pods, communicates with API server.
  - **kube-proxy**: Handles networking (e.g., service load balancing).
  - **Container Runtime**: Executes containers (e.g., containerd, Docker).
- **Interactions**:
  - API server mediates between components (e.g., kubelet reports to API server, scheduler queries API).
  - etcd stores all persistent state, critical for API server functionality.
  - Failures in one component (e.g., etcd) can affect others (e.g., API server errors).
- **Health Checks**:
  - `kubectl get nodes`: Node status (`Ready`, `NotReady`).
  - `kubectl cluster-info`: API server and CoreDNS endpoints.
  - `kubectl get componentstatus`: Legacy command for control plane health (less common in v1.29+).

#### Node Issues
- **Statuses**:
  - `Ready`: Node is healthy, can schedule pods.
  - `NotReady`: Node cannot schedule new pods (e.g., kubelet down, resource issues).
  - Missing: Node not registered (e.g., network or kubelet failure).
- **Conditions** (via `kubectl describe node`):
  - `OutOfDisk`: No disk space for new pods.
  - `MemoryPressure`: Low memory, may evict pods.
  - `DiskPressure`: Low disk, may evict pods.
  - `PIDPressure`: Too many processes.
  - `NetworkUnavailable`: CNI plugin issues.
- **Common Causes**:
  - Kubelet crash (e.g., misconfiguration, resource exhaustion).
  - Network issues (e.g., CNI failure, DNS errors).
  - Resource shortages (disk, memory, CPU).
- **Maintenance**:
  - `kubectl cordon <node>`: Marks node unschedulable.
  - `kubectl drain <node>`: Evicts pods, then cords.
  - `kubectl uncordon <node>`: Re-enables scheduling.
- **Eviction Policies**:
  - Kubelet evicts pods based on QoS (BestEffort first, then Burstable, Guaranteed last).
  - Triggered by thresholds (e.g., memory.available < 100Mi).

#### Control Plane Issues
- **Deployment**:
  - **Static Pods**: Run directly by kubelet (e.g., `/etc/kubernetes/manifests`).
  - **Pods in `kube-system`**: Managed by DaemonSets or Deployments (e.g., in managed clusters like EKS).
- **Common Issues**:
  - **kube-apiserver**: Authentication errors, network issues, etcd downtime.
  - **etcd**: Quorum loss, disk latency, corruption.
  - **kube-scheduler/controller-manager**: Misconfiguration, resource limits.
- **Diagnostics**:
  - `kubectl get pods -n kube-system`: Check pod status.
  - `kubectl logs <pod> -n kube-system`: Component logs.
  - etcd: Use `etcdctl` or check pod logs for errors.

#### Exam Relevance
- **High Weight**: Cluster and node troubleshooting is central to CKA, with tasks like fixing `NotReady` nodes or control plane pods.
- **Practical Focus**: Expect to use `kubectl`, system logs, and node access (e.g., SSH or debug pods).
- **Version Notes**: v1.29+ uses containerd, systemd-based logging; static pods are common for control plane.

---

### 3. YAML Examples
Troubleshooting often involves inspecting existing resources or creating debug pods rather than writing new YAMLs. Below are examples for debugging and simulating issues.

#### Example 1: Debug Pod for Node Access
```yaml
# File: troubleshoot/debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: debug-pod
  namespace: kube-system
spec:
  containers:
  - name: debug
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:
    - name: host-logs
      mountPath: /host-logs
    - name: host-bin
      mountPath: /host-bin
  volumes:
  - name: host-logs
    hostPath:
      path: /var/log
  - name: host-bin
    hostPath:
      path: /usr/bin
  nodeName: <node-name> # Replace with troubled node
```

**Critical Fields**:
- `spec.volumes.hostPath`: Mounts node logs (`/var/log`) and tools (`/usr/bin`).
- `spec.nodeName`: Targets specific node for debugging.
- `spec.containers.command`: Keeps pod running.

#### Example 2: Simulate Node Issue (Pod with High Resource Usage)
```yaml
# File: troubleshoot/stress-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: stress-pod
  namespace: default
spec:
  containers:
  - name: stress
    image: polinux/stress
    command: ["stress", "--vm", "1", "--vm-bytes", "2G"]
    resources:
      requests:
        memory: "1Gi"
        cpu: "1"
      limits:
        memory: "2Gi"
        cpu: "2"
```

**Purpose**: Simulates memory pressure to practice node troubleshooting.

---

### 4. Critical Commands
Troubleshooting relies on `kubectl` and Linux commands. Key commands include:

| Command | Description | Exam Tip |
|---------|-------------|----------|
| `kubectl get nodes` | Check node status (`Ready`, `NotReady`). | First step for node issues. |
| `kubectl describe node <node>` | Node conditions and events. | Look for `MemoryPressure`, etc. |
| `kubectl cluster-info` | API server and CoreDNS status. | Verify control plane access. |
| `kubectl get pods -n kube-system` | Control plane pod health. | Check for `CrashLoopBackOff`. |
| `kubectl logs <pod> -n kube-system` | Control plane pod logs. | Use `--previous` for crashes. |
| `kubectl cordon <node>` | Mark node unschedulable. | Use before maintenance. |
| `kubectl drain <node> --ignore-daemonsets` | Evict pods, cordon node. | Common for node fixes. |
| `kubectl uncordon <node>` | Re-enable scheduling. | Post-maintenance step. |
| `journalctl -u kubelet` | Kubelet logs. | Debug node registration. |
| `systemctl status kubelet` | Kubelet service status. | Check if running. |
| `crictl ps` | List running containers. | Debug container runtime. |
| `etcdctl endpoint health` | Check etcd health. | Requires etcd access. |

---

### 5. Step-by-Step Diagnostics
Hereâ€™s how to troubleshoot a node in `NotReady` state and a control plane issue.

#### Scenario 1: Node NotReady
**Step 1: Check Node Status**
```bash
kubectl get nodes
# Output: NAME       STATUS     ROLES    AGE   VERSION
#         node-1    NotReady   <none>   1d    v1.29.0
```

**Step 2: Inspect Node Conditions**
```bash
kubectl describe node node-1
# Conditions:
#   Type             Status  LastTransitionTime  Reason
#   ----             ------  ------------------  ------
#   MemoryPressure   True    ...                 LowMemory
```

**Step 3: Access Node Logs**
- Use debug pod or SSH (exam may provide access).
```bash
kubectl apply -f troubleshoot/debug-pod.yaml
kubectl exec -it debug-pod -n kube-system -- sh
# Inside pod:
cat /host-logs/kubelet.log
# Look for: "Memory pressure detected"
journalctl -u kubelet
# Look for: "OOM killer invoked"
```

**Step 4: Check Resource Usage**
```bash
# Inside debug pod:
top
# Identify high-memory process (e.g., stress-pod)
kubectl get pods --all-namespaces
# Find culprit: stress-pod
```

**Step 5: Fix Issue**
```bash
kubectl delete pod stress-pod -n default
# Or reduce resource usage
kubectl describe node node-1
# Confirm: MemoryPressure=False
kubectl get nodes
# Output: STATUS: Ready
```

#### Scenario 2: Control Plane Pod Crash
**Step 1: Check Control Plane**
```bash
kubectl get pods -n kube-system
# Output: NAME                            READY   STATUS             RESTARTS
#         kube-apiserver-master-1         0/1     CrashLoopBackOff   5
```

**Step 2: Inspect Pod**
```bash
kubectl describe pod kube-apiserver-master-1 -n kube-system
# Events: "Failed to start container: invalid flag"
```

**Step 3: Check Logs**
```bash
kubectl logs kube-apiserver-master-1 -n kube-system --previous
# Output: "Error: --authentication-mode invalid"
```

**Step 4: Fix Issue**
- Static pod: Edit manifest.
```bash
# Access master node (via debug pod or SSH)
kubectl exec -it debug-pod -n kube-system -- sh
vi /host-logs/kubernetes/manifests/kube-apiserver.yaml
# Fix: Remove invalid flag
```

- Restart kubelet (if needed):
```bash
systemctl restart kubelet
```

**Step 5: Verify**
```bash
kubectl get pods -n kube-system
# Output: STATUS: Running
```

---

### 6. Exam-Style Questions
Below are CKA-style questions to practice, with estimated times and answers.

#### Question 1: Task-Based (6 minutes)
**Task**: A node named `node-2` is in `NotReady` state. Identify and fix the issue.

**Steps**:
```bash
kubectl get nodes
# Output: node-2   NotReady   <none>   1d   v1.29.0

kubectl describe node node-2
# Condition: DiskPressure=True

# Debug pod
kubectl apply -f troubleshoot/debug-pod.yaml
kubectl exec -it debug-pod -n kube-system -- sh
df -h
# Output: /host-logs 100% used

# Fix: Clean disk
rm /host-logs/large-file.log

# Verify
kubectl get nodes
# Output: node-2   Ready
```

#### Question 2: Troubleshooting (8 minutes)
**Task**: The API server pod in `kube-system` is in `CrashLoopBackOff`. Debug and fix it.

**Steps**:
```bash
kubectl get pods -n kube-system
# Output: kube-apiserver-master-1   0/1   CrashLoopBackOff

kubectl describe pod kube-apiserver-master-1 -n kube-system
# Events: "Failed to start: etcd endpoint unreachable"

kubectl logs kube-apiserver-master-1 -n kube-system --previous
# Output: "etcd: connection refused"

# Check etcd
kubectl get pods -n kube-system | grep etcd
# Output: etcd-master-1   0/1   Error

# Fix etcd (example: wrong endpoint)
kubectl exec -it debug-pod -n kube-system -- sh
vi /host-logs/kubernetes/manifests/etcd.yaml
# Correct: --advertise-client-urls

# Restart kubelet
systemctl restart kubelet

# Verify
kubectl get pods -n kube-system
# Output: STATUS: Running
```

#### Question 3: Validation (4 minutes)
**Task**: Confirm all nodes are `Ready` and control plane components are running.

**Steps**:
```bash
kubectl get nodes
# Output: NAME       STATUS   ROLES    AGE   VERSION
#         master-1   Ready    control-plane   1d    v1.29.0
#         node-1     Ready    <none>          1d    v1.29.0

kubectl get pods -n kube-system
# Output: All Running (e.g., kube-apiserver, etcd, scheduler)
```

---

### 7. Important Key Points to Remember
- **Cluster Architecture**:
  - Control plane: API server, scheduler, controller manager, etcd.
  - Worker nodes: Kubelet, kube-proxy, container runtime.
  - Interactions: API server is central; etcd stores state.
- **Node Issues**:
  - Statuses: `Ready`, `NotReady`, missing.
  - Conditions: `MemoryPressure`, `DiskPressure`, `NetworkUnavailable`.
  - Maintenance: `cordon`, `drain`, `uncordon`.
  - Evictions: Based on QoS (BestEffort, Burstable, Guaranteed).
- **Control Plane Issues**:
  - Run as static pods or in `kube-system`.
  - Common failures: API server (auth, etcd), etcd (quorum, latency).
  - Logs: `kubectl logs`, `/var/log/kubernetes`.
- **Diagnostics**:
  - `kubectl get/describe`: Nodes, pods, events.
  - `journalctl`, `systemctl`: Node services.
  - `crictl`: Container runtime.
- **Exam Focus**:
  - Fix `NotReady` nodes, control plane crashes.
  - Use `describe` for events, `logs` for details.
  - Quick node access (SSH, debug pods).
- **Version Note**:
  - v1.29+: Containerd default, systemd logs, static pods for control plane.

---

### 8. Common Mistakes to Avoid
- **Mistake**: Ignoring `kubectl describe` events.
  - **Fix**: Always start with `describe node/pod` for context.
- **Mistake**: Forgetting `-n kube-system` for control plane pods.
  - **Fix**: Use `-n` or `--all-namespaces`.
- **Mistake**: Not checking node logs for kubelet issues.
  - **Fix**: Use `journalctl -u kubelet` or `/var/log/kubelet.log`.
- **Mistake**: Draining node without `--ignore-daemonsets`.
  - **Fix**: Include `--ignore-daemonsets` to handle system pods.
- **Mistake**: Misdiagnosing etcd vs. API server issues.
  - **Fix**: Check etcd logs/pod first if API fails.

**Exam Traps**:
- Missing `--force` or `--grace-period` in `drain` for stuck pods.
- Not validating fixes with `kubectl get`.
- Spending too long on one component (balance node vs. control plane).

---

### 9. Troubleshooting Tips
- **Node NotReady**:
  - Check: `kubectl describe node`
  - Causes:
    - Kubelet down (`systemctl status kubelet`).
    - Resource pressure (`top`, `df`).
    - Network/CNI failure (`journalctl -u flannel`).
  - Fix: Restart kubelet, free resources, fix CNI.
- **Control Plane Crash**:
  - Check: `kubectl describe pod -n kube-system`
  - Causes:
    - Misconfiguration (e.g., wrong flags).
    - etcd failure (`etcdctl endpoint health`).
    - Resource limits (`OOMKilled`).
  - Fix: Edit manifests, restart kubelet, adjust resources.
- **Node Missing**:
  - Check: `kubectl get nodes`
  - Causes:
    - Kubelet not running.
    - Network isolation.
    - Wrong API server endpoint.
  - Fix: Start kubelet, check network, verify kubelet config.
- **Tools**:
  - `kubectl describe/get`: Cluster state.
  - `journalctl`, `/var/log`: Node logs.
  - `crictl ps/logs`: Container runtime.
  - `systemctl`: Service status.

**Debugging Checklist**:
1. Check nodes (`kubectl get nodes`).
2. Inspect conditions (`kubectl describe node`).
3. Verify control plane (`kubectl get pods -n kube-system`).
4. Review logs (`kubectl logs`, `journalctl`).
5. Test fixes (`kubectl get`).

---

### 10. Additional Resources
- **Kubernetes Docs**:
  - [Debug Cluster](https://kubernetes.io/docs/tasks/debug/debug-cluster/)
  - [Node Troubleshooting](https://kubernetes.io/docs/tasks/administer-cluster/troubleshoot-cluster/)
  - [Control Plane](https://kubernetes.io/docs/concepts/overview/components/)
- **Practice Tools**:
  - **Minikube**: Simulate node failures.
  - **KillerCoda/KodeKloud**: CKA-style labs.
  - **Kind**: Multi-node clusters for control plane issues.
- **Community**:
  - CNCF Slack: #kubernetes-users, #cka-prep.
  - Kubernetes GitHub: Issues for troubleshooting.
  - X posts: Search #KubernetesTroubleshooting, #CKA.

---

### 11. GitHub Repo Integration
Hereâ€™s how to organize this topic in your GitHub repo.

#### Folder Structure
```
cka-prep/
â”œâ”€â”€ storage/
â”œâ”€â”€ troubleshoot/
â”‚   â”œâ”€â”€ debug-pod.yaml
â”‚   â”œâ”€â”€ stress-pod.yaml
â”‚   â”œâ”€â”€ README.md
â”œâ”€â”€ README.md
```

#### README Content (troubleshoot/README.md, Updated)
```markdown
# Troubleshoot: Troubleshoot Clusters and Nodes

## Theory
- **Cluster**: Control plane (API server, etcd) and nodes (kubelet, kube-proxy).
- **Node Issues**: `NotReady`, resource pressure, kubelet crashes.
- **Control Plane**: Pod crashes, etcd quorum loss.

## YAML Examples
- `debug-pod.yaml`: Access node logs/tools.
- `stress-pod.yaml`: Simulate memory pressure.

## Diagnostics
1. Check nodes: `kubectl get nodes`
2. Inspect: `kubectl describe node`
3. Control plane: `kubectl get pods -n kube-system`
4. Logs: `journalctl -u kubelet`
5. Fix: Restart kubelet, clean disk, edit manifests.

## Key Points
- `describe node` shows conditions (`DiskPressure`).
- `cordon`/`drain` for maintenance.
- Control plane in `kube-system` or static pods.

## Common Mistakes
- Missing `-n kube-system`.
- Ignoring node logs.
- Wrong `drain` flags.

## Troubleshooting
- `NotReady`? Check `kubectl describe node`, `journalctl`.
- API crash? Logs in `kube-system`, check etcd.

## Questions
1. Fix `NotReady` node.
2. Debug API server `CrashLoopBackOff`.
3. Verify cluster health.
```

#### File Comments (debug-pod.yaml)
```yaml
# debug-pod.yaml
# Debug pod for node logs (/var/log) and tools (/usr/bin)
# Verify: kubectl exec debug-pod -- journalctl -u kubelet
# Use: For node and control plane issues
```

---

### Comprehensive Summary
This topic lays the foundation for Kubernetes troubleshooting by focusing on cluster and node diagnostics. Youâ€™ve learned:
- The roles of control plane and node components, and how they fail.
- How to diagnose `NotReady` nodes using conditions and logs.
- How to troubleshoot control plane issues via `kube-system` pods and manifests.
- Practical skills like cordon/drain and log inspection.

**Practice Plan**:
- Deploy `stress-pod.yaml` to simulate node issues (Minikube, Kind).
- Break a node (e.g., stop kubelet, fill disk) and fix it.
- Use `debug-pod.yaml` to practice log access.
- Time yourself on the exam questions (<20 minutes total).

**Next Steps**:
- Move to the next troubleshooting topic (e.g., â€œTroubleshoot Application Failuresâ€).
- Practice mixed scenarios (e.g., node + control plane issues).
- Let me know if you want more debug YAMLs or specific failure simulations.

---

This response covers **Troubleshoot Clusters and Nodes** comprehensively, tailored for your CKA prep and GitHub repo. Thanks for the clarificationâ€”Iâ€™m glad weâ€™re on track! Please share the next topic (e.g., second troubleshooting topic), and Iâ€™ll keep delivering. Any tweaks or focus areas (e.g., more etcd scenarios)? Letâ€™s keep this prep unstoppable! ðŸ˜Š
